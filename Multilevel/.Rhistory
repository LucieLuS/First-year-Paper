## To make the pdf file do
## render("exploration4.Rmd",output_format=pdf_document())
require(knitr)
opts_chunk$set(
tidy=FALSE,     # display code as typed
size="small",    # slightly smaller font for code
echo=TRUE,
results='markup',
strip.white=TRUE,
fig.path='figs/fig',
cache=FALSE,
highlight=TRUE,
width.cutoff=132,
size='footnotesize',
out.width='.9\\textwidth',
message=FALSE,
comment=NA)
options(knitr.graphics.auto_pdf = TRUE)
##First, just setup the R environment for today:
if(!file.exists('figs')) dir.create('figs')
options(SweaveHooks=list(fig=function(){
par(mar=c(3.5, 3, 1.1, 0),
pty="s",
mgp=c(1.5,0.5,0),
oma=c(0,0,0,0))},
echo=function(){options(continue=" ") ##Don't show "+" prompts,
options(prompt=" ")
}),
digits=4,
scipen=8,
width=132
)
options(error=function(){options(prompt="> ",continue="+ ");NULL})
#To prepare the environment
library(readstata13)
library(dplyr)
library(ggplot2)
#install.packages("ggrepel")
library(ggrepel)
library(stargazer)
#install.packages("devtools")
library(devtools)
library(foreign)
#install.packages("gplots")
library(gplots)
library(lmtest)
library(sandwich)
suppressMessages(library("tidyverse"))
library(MASS)
library(robustbase)
#install.packages("rmngb")
library(rmngb)
library(here)
#devtools::install_github("ropenscilabs/gramr")
library("gramr")
#write_good_ip()
library(arm)
#install.packages("effects")
library(effects)
library(ROCR)
library(multiwayvcov)
#devtools::install_github("rstudio/rmarkdown")
#install.packages("stringi",type="win.binary")
#install.packages("kableExtra")
#install.packages("magrittr")
library(kableExtra)
library(magrittr)
knitr::opts_chunk$set(echo = TRUE)
getwd()
set_here(path=".", verbose=T)
here()
list.files(path=".")
mydata_10_all <- read.csv("mydata10all_matching_3.csv") #286 observations
#View(mydata_10_all)
table(mydata_10_all$Z) #93 events
length(unique(mydata_10_all$ccode)) #62 countries
table(mydata_10_all$GDPdecline) #79 leaders experiencing decline
n_leader <- nrow(mydata_10_all) #286 leaders
#factorize Z
mydata_10_all$Z <- as.factor(mydata_10_all$Z)
percent_leader0 <- round((table(mydata_10_all$Z)[1]/n_leader)*100,2) #67.48%
percent_leader1 <- round((table(mydata_10_all$Z)[2]/n_leader)*100,2) #32.52%
percent_leader0 #leaders without shocks
percent_leader1 #leaders with shocks
#########
#nondemocratic regimes:
mydata_10_auto <- subset(mydata_10_all, !DICT3=="democracy") #77 leaders in no authority plus autocracies
n_leader_auto <- nrow(mydata_10_auto)
percent_leader0_auto <- round((table(mydata_10_auto$Z)[1]/n_leader_auto)*100,2) #64%
percent_leader1_auto <- round((table(mydata_10_auto$Z)[2]/n_leader_auto)*100,2) #36%
percent_leader0_auto #leaders without shocks
percent_leader1_auto #leaders with shocks
##########
#democratic regimes:
mydata_10_dem <- subset(mydata_10_all, DICT3=="democracy") #209 in electoral democrcies (limited form of democracy)
n_leader_dem <- nrow(mydata_10_dem)
percent_leader0_dem <- round((table(mydata_10_dem$Z)[1]/n_leader_dem)*100,2) #69%
percent_leader1_dem <- round((table(mydata_10_dem$Z)[2]/n_leader_dem)*100,2) #31%
percent_leader0_dem #leaders without shocks
percent_leader1_dem #leaders with shocks
dis_Z_event <- table(mydata_10_all$Z, mydata_10_all$event)
dis_Z_event[1,1] #142
dis_Z_event[1,2] #51
dis_Z_event[2,1] #52
dis_Z_event[2,2] #41
percent_leader0_event <- round(((dis_Z_event[1,2])/(dis_Z_event[1,2]+dis_Z_event[1,1]))*100,2) #26%
percent_leader1_event <- round(((dis_Z_event[2,2])/(dis_Z_event[2,1]+dis_Z_event[2,2]))*100,2) #44%
mydata10_all_ggplot2 <- na.omit(mydata_10_all[,c("Z", "event", "DICT3")])
mydata10_all_ggplot2$Z <- as.factor(mydata10_all_ggplot2$Z)
mydata10_all_ggplot2 <- ggplot(data=mydata10_all_ggplot2, aes(x=Z, y=event, color = DICT3))
mydata10_all_ggplot2  +
geom_point(position=position_jitter(height=0.2, width=0.2)) + theme_bw() +
labs(x="Shock to Security", y = "Probability of PTAs Negotiation (%)") +
ggtitle("Dsitributions of Leaders across Regime Types \n Divided by Shock to Security") +
theme(plot.title = element_text(face="bold", size=16, hjust = 0.5)) +
annotate("text", x = 1:2, y = 0.5, label = c("26%", "44%")) +
scale_x_discrete(breaks=c("0","1"), labels=c("No Shock", "With Shock"))
dis_Z_event_auto <- table(mydata_10_auto$Z, mydata_10_auto$event)
dis_Z_event_auto[1,1] #142
dis_Z_event_auto[1,2] #51
dis_Z_event_auto[2,1] #52
dis_Z_event_auto[2,2] #41
percent_leader0_event_auto <- round(((dis_Z_event_auto[1,2])/(dis_Z_event_auto[1,2]+dis_Z_event_auto[1,1]))*100,2) #37%
percent_leader1_event_auto <- round(((dis_Z_event_auto[2,2])/(dis_Z_event_auto[2,1]+dis_Z_event_auto[2,2]))*100,2) #64%
percent_leader0_event_auto
percent_leader1_event_auto
dis_Z_event_dem <- table(mydata_10_dem$Z, mydata_10_dem$event)
dis_Z_event_dem[1,1] #111
dis_Z_event_dem[1,2] #33
dis_Z_event_dem[2,1] #42
dis_Z_event_dem[2,2] #23
percent_leader0_event_dem <- round(((dis_Z_event_dem[1,2])/(dis_Z_event_dem[1,2]+dis_Z_event_dem[1,1]))*100,2) #23%
percent_leader1_event_dem <- round(((dis_Z_event_dem[2,2])/(dis_Z_event_dem[2,1]+dis_Z_event_dem[2,2]))*100,2) #35%
percent_leader0_event_dem
percent_leader1_event_dem
#install.packages("xtable",repos = "http://cran.us.r-project.org")
library(xtable)
percent_Z <- c(percent_leader1, percent_leader1_dem, percent_leader1_auto)
percent_Z_event <- c(percent_leader1_event, percent_leader1_event_dem, percent_leader1_event_auto)
percentages <- as.matrix(rbind(percent_Z, percent_Z_event))
row_names_percentages <- c("Percentages of leaders being treated (%)", "Percentages of those treated negotiated a PTA (%)")
col_names_percentages <- c("All Regime Types", "Democracies", "Nondemocracies")
rownames(percentages) <- row_names_percentages
colnames(percentages) <- col_names_percentages
xtable(percentages)
knitr::kable(percentages, caption = "\\label{tab:per} Percentages of Leaders Having a Shock and those not and Percentages of PTA Negotiation", format = "latex", booktabs = TRUE) %>%
kable_styling(latex_options = "scale_down")
#locate the missing values
colSums(is.na(mydata_10_all))
#which(is.na(mydata_10_all$AUTODUR))
#recode missing value with the means
mydata_10_all$PTS_A.x[is.na(mydata_10_all$PTS_A.x)] <- mean(mydata_10_all$PTS_A.x, na.rm = TRUE)
mydata_10_all$GDPpercapita[is.na(mydata_10_all$GDPpercapita)] <- mean(mydata_10_all$GDPpercapita, na.rm = TRUE)
mydata_10_all$v2x_libdem[is.na(mydata_10_all$v2x_libdem)] <- mean(mydata_10_all$v2x_libdem, na.rm = TRUE)
library(MASS)
library(RItools)
library(optmatch)
#Balance check
mydata_10_all$Z <- as.numeric(as.character(mydata_10_all$Z))
class(mydata_10_all$Z)
balcheck_all <- reformulate(c(names(mydata_10_all)[c(22, 23, 24, 25, 26)], "poleff"), response = "Z")
xbalance0_all<-xBalance(balcheck_all,
data=mydata_10_all,
report=c("std.diffs","z.scores","adj.means",
"adj.mean.diffs", "chisquare.test","p.values"))
xbalance0_all
#mydata_10_all$Z <- as.factor(mydata_10_all$Z)
#Ordinary propensity score
glm_propensity_all <- glm(Z ~ v2x_libdem + GDPpercapita + PTS_A.x + DEMDUR + AUTODUR + poleff, data=mydata_10_all, family = "binomial")
round(summary(glm_propensity_all)$coeff, 2)
## Rank-Based Mahalanobis distance (Rosenbaum, Chap 8) doesn't require a propensity model to collapse all of the variables down to a simple score and thus distance
mydata_10_all$Z <- as.numeric(mydata_10_all$Z)
mhdist_propensity_all <- match_on(balcheck_all, data=mydata_10_all, method="rank_mahalanobis")
as.matrix(mhdist_propensity_all)[1:5,1:5]
##add it back to the data
mydata_10_all$pscore <- predict(glm_propensity_all)
#check coeff
logitcoef_all <- round(coef(glm_propensity_all),2)
#Make distance matrice
psdist_glm_all <- match_on(Z ~ pscore,data=mydata_10_all)
as.matrix(psdist_glm_all)[1:5,1:5]
dim(psdist_glm_all) #93*193
#The standard deviation of the propensity score
sd(mydata_10_all$pscore) #1.767
0.2*sd(mydata_10_all$pscore) #0.3534 caliper
#before matching, check it
with(mydata_10_all, boxplot(split(pscore, Z),main="Estimated Propensity Scores before Matching"))
#full matching
fm1_p_all <- fullmatch(mhdist_propensity_all, data = mydata_10_all) ##, min.controls=1) # min.controls=.5
summary(fm1_p_all, data=mydata_10_all, min.controls=0, max.controls=Inf)
length(fm1_p_all) #286
#matched(fm1_p_all) #all are matched
## We have to show that we have adjusted enough. Did we adjust enough?
xb1_p_all <- xBalance(update(balcheck_all, .~.+strata(fm1_p_all)), data=mydata_10_all,
report=c("std.diffs","z.scores","adj.means", "adj.mean.diffs", "chisquare.test","p.values"))
xb1_p_all
#It seems that it's a little bit better.
#Add it back to the data
#mydata_10_aut$fm1_p <- fm1_p
#addingcaliper?
glm_propensity.dist_all <- match_on(glm_propensity_all)
as.matrix(glm_propensity.dist_all)[1:5,1:5]
caldist_all <- caliper (glm_propensity.dist_all, width = .2)
#mhd.pptyc <- caliper(mhdist_propensity, width =1)
#full matching
fm2_p_all <- fullmatch(mhdist_propensity_all + caldist_all , data = mydata_10_all) ##, min.controls=1) # min.controls=.5
summary(fm2_p_all,data=mydata_10_all,min.controls=0,max.controls=Inf)
#check balance
xb2_p_all <- xBalance(update(balcheck_all, .~. + strata(fm2_p_all)), data=mydata_10_all,
report=c("std.diffs","z.scores", "adj.means", "adj.mean.diffs", "chisquare.test","p.values"))
xb2_p_all_results <- round(xb2_p_all$results,2)
xb2_p_all_overall <- round(xb2_p_all$overall,2)
round(xb2_p_all$results["poleff",,],2)
## In the fm2 design, treated units and control units differed by about .06 baseline political effectiveness score on average
#(or differed by about .08 sds in baseline baseline political effectiveness score)
round(xb2_p_all$results["PTS_A.x",,],2)
## In the fm2 design, treated units and control units' PTS scores are the same.
##What's left unbalanced is authoritarian regime's tenure.
#install.packages("xtable",repos = "http://cran.us.r-project.org")
library(xtable)
xb1.xtab <- xtable(xb2_p_all)
rownames(xb1.xtab) <- c("Democracy Index", "GDP per capita", "PTS Score", "Duration of Democracy", "Duration of Autocracy", "Political Effectiveness Score")
knitr::kable(xb1.xtab, caption = "\\label{tab:xb1} Test Balance on Covariates before and after Matching", format = "latex", booktabs = TRUE,
format.args=list(big.mark=",",  floats = "h")) %>%
kableExtra::kable_styling(latex_options = "scale_down")
#install.packages("xtable",repos = "http://cran.us.r-project.org")
library(xtable)
xb2.xtab <- xtable(xb2_p_all_overall)
rownames(xb2.xtab) <- c("Pre-Matching", "Post-Matching")
knitr::kable(xb2.xtab, caption = "\\label{tab:xb2} Test Balance before and after Matching", format = "latex", booktabs = TRUE,
format.args=list(big.mark=",", floats = "h")) %>%
kable_styling(latex_options = "basic", font_size=11)
## Estimating the average treatment effect of the intervention after adjusting for the 5 obsserved variables as specified above.
lm2_all<-lm(event ~ Z + fm2_p_all, data=mydata_10_all)
summary(lm2_all)
coef(lm2_all)["Z"] #0.23 #as expected
#mydata_10_all$GDPdecline <- as.factor(mydata_10_all$GDPdecline)
#class (mydata_10_all$GDPdecline)
#Final model
c.tenure <- mydata_10_all$tenure - mean(mydata_10_all$tenure)
mydata_10_all$Z <- as.factor(mydata_10_all$Z)
mydata_10_all$GDPdecline <- as.factor(mydata_10_all$GDPdecline)
lm3_all <- lm(event ~ Z + GDPdecline + c.tenure + fm2_p_all, data=mydata_10_all)
summary(lm3_all)
coef(lm3_all)["Z1"] #0.15 #as expected
library(stargazer)
#Now use stargazer to format the linear model
stargazer(lm3_all, header = FALSE, df = FALSE, omit = "fm2_p_all", intercept.bottom = F,
title = "Ordinary Linear Squared Regression Model (After Full Matching): Results",
covariate.labels = c("Constant", "Shock to Security", "Economic Recession","Mean Tenure"),
dep.var.labels = "Preferential Trade Agreement Negotation Rate",
column.sep.width = "0.3pt", no.space = TRUE, font.size = "footnotesize", notes = "Automatic reporting p-values, need to be replaced with Fishers' Null")
eff_fit_matching <- allEffects(lm3_all)
dataf_eff_fit_matching <- as.data.frame(eff_fit_matching$Z)
OLS_event_leader0 <- round((dataf_eff_fit_matching$fit[1])*100,2)
OLS_event_leader1 <- round((dataf_eff_fit_matching$fit[2])*100,2)
ggplot(dataf_eff_fit_matching , aes(Z, fit)) + geom_point() + coord_cartesian(ylim = c(0, 0.6)) + geom_errorbar(aes(ymin=fit-se, ymax=fit+se), width=0.4) + theme_bw(base_size=12) + labs(x="Shocks to Security", y = "Probability of PTAs Negotiation (%)") + ggtitle("Treatment Effects on Leaders After Matching") + theme(plot.title = element_text(face="bold", size=15, hjust = 0.5)) + scale_x_discrete(breaks=c("0","1"), labels=c("No Shock", "With Shock"))
cat("\\newpage")
cat("\\newpage")
mydata_test$Country <- as.factor(mydata_10_all$Country)
mydata_10_all$Country <- as.factor(mydata_10_all$Country)
mydata_10_all$country <- as.factor(mydata_10_all$country)
mydata_10_all
mydata_10_all$country <- as.factor(mydata_10_all$ccname)
mydata_10_all
vcov_c <- cluster.vcov(lm3_all, mydata_5test$CountryF)
vcov_c <- cluster.vcov(lm3_all, mydata_10_all$country)
coeftest(lm3_all, vcov_c)
vcovWBC_c <- cluster.boot(lm3_all, cluster=mydata_10_all$country, boot_type="wild")
coeftest(lm3_all, vcovWBC_c)
vcov_hc0 <- cluster.vcov(lm3_all, 1:nrow(mydata_10_all), df_correction = FALSE)
coeftest(lm3_all, vcov_hc0)
vcov_hc1 <- cluster.vcov(lm3_all, 1:nrow(mydata_10_all), df_correction = TRUE)
coeftest(lm3_all, vcov_hc1)
vcov_hc2 <- cluster.vcov(lm3_all, 1:nrow(mydata_10_all), df_correction = FALSE, leverage = 2)
coeftest(lm3_all, vcov_hc2)
vcov_hc2 <- cluster.vcov(lm3_all, 1:nrow(mydata_10_all), df_correction = FALSE, leverage = 2)
coeftest(lm3_all, vcov_hc2)
vcov_hc3 <- cluster.vcov(lm3_all, 1:nrow(mydata_10_all), df_correction = FALSE, leverage = 3)
coeftest(lm3_all, vcov_hc3_cm)
vcov_hc3 <- cluster.vcov(lm3_all, 1:nrow(mydata_10_all), df_correction = FALSE, leverage = 3)
coeftest(lm3_all, vcov_hc3)
vcov_hc1 <- cluster.vcov(lm3_all, 1:nrow(mydata_10_all), df_correction = TRUE)
coeftest(lm3_all, vcov_hc1)
vcov_hc0 <- cluster.vcov(lm3_all, 1:nrow(mydata_10_all), df_correction = FALSE)
coeftest(lm3_all, vcov_hc0)
vcovWBC_c <- cluster.boot(lm3_all, cluster=mydata_10_all$country, boot_type="wild")
coeftest(lm3_all, vcovWBC_c)
vcov_c <- cluster.vcov(lm3_all, mydata_10_all$country)
coeftest(lm3_all, vcov_c)
vcov_hc0
lm3_all, vcov_hc0
coeftest(lm3_all, vcov_hc0)
vcov_hc0
robust_se <- sqrt (diag(vcov_hc0))
robust_se
library(stargazer)
#Now use stargazer to format the linear model
stargazer(lm3_all, header = FALSE, df = FALSE, omit = "fm2_p_all", intercept.bottom = F,
title = "Ordinary Linear Squares Regression Model (After Full Matching): Results", se = robust_se,
covariate.labels = c("Constant", "Shock to Security", "Economic Recession","Mean Tenure"),
dep.var.labels = "Preferential Trade Agreement Negotation Rate",
omit.stat = "f",
column.sep.width = "0.3pt", no.space = TRUE, font.size = "footnotesize", notes = "Clustered Robust Standard Errors")
library(stargazer)
#Now use stargazer to format the linear model
stargazer(lm3_all, header = FALSE, df = FALSE, omit = "fm2_p_all", intercept.bottom = F,
title = "Ordinary Linear Squares Regression Model (After Full Matching): Results", se = robust_se_spellout,
covariate.labels = c("Constant", "Shock to Security", "Economic Recession","Mean Tenure"),
dep.var.labels = "Preferential Trade Agreement Negotation Rate",
omit.stat = "f",
column.sep.width = "0.3pt", no.space = TRUE, font.size = "footnotesize", notes = "Clustered Robust Standard Errors")
robust_se_spellout <- c(0.072, 0.085, 0.064, 0.007)
library(stargazer)
#Now use stargazer to format the linear model
stargazer(lm3_all, header = FALSE, df = FALSE, omit = "fm2_p_all", intercept.bottom = F,
title = "Ordinary Linear Squares Regression Model (After Full Matching): Results", se = robust_se_spellout,
covariate.labels = c("Constant", "Shock to Security", "Economic Recession","Mean Tenure"),
dep.var.labels = "Preferential Trade Agreement Negotation Rate",
omit.stat = "f",
column.sep.width = "0.3pt", no.space = TRUE, font.size = "footnotesize", notes = "Clustered Robust Standard Errors")
# Adjust F statistic
wald_results <- waldtest(lm3_all, vcov = vcov_hc0)
library(stargazer)
#Now use stargazer to format the linear model
stargazer(lm3_all, header = FALSE, df = FALSE, omit = "fm2_p_all", intercept.bottom = F,
title = "Ordinary Linear Squares Regression Model (After Full Matching): Results", se = list(robust_se),
covariate.labels = c("Constant", "Shock to Security", "Economic Recession","Mean Tenure"),
dep.var.labels = "Preferential Trade Agreement Negotation Rate",
omit.stat = "f",
column.sep.width = "0.3pt", no.space = TRUE, font.size = "footnotesize", notes = "Clustered Robust Standard Errors")
robust_se <- sqrt (diag(vcov_hc0))
eff_fit_matching <- allEffects(lm3_all)
dataf_eff_fit_matching <- as.data.frame(eff_fit_matching$Z)
OLS_event_leader0 <- round((dataf_eff_fit_matching$fit[1])*100,2)
OLS_event_leader1 <- round((dataf_eff_fit_matching$fit[2])*100,2)
ggplot(dataf_eff_fit_matching , aes(Z, fit)) + geom_point() + coord_cartesian(ylim = c(0, 0.6)) + geom_errorbar(aes(ymin=fit-se, ymax=fit+se), width=0.4) + theme_bw(base_size=12) + labs(x="Shocks to Security", y = "Probability of PTAs Negotiation (%)") + ggtitle("Treatment Effects on Leaders After Matching") + theme(plot.title = element_text(face="bold", size=15, hjust = 0.5)) + scale_x_discrete(breaks=c("0","1"), labels=c("No Shock", "With Shock"))
eff_fit_matching <- allEffects(lm3_all)
dataf_eff_fit_matching <- as.data.frame(eff_fit_matching$Z)
OLS_event_leader0 <- round((dataf_eff_fit_matching$fit[1])*100,2)
OLS_event_leader0
OLS_event_leader1
dataf_eff_fit_matching
lm3_all_2 <- lm(event ~ GDPdecline + c.tenure + fm2_p_all, data=mydata_10_all)
summary(lm3_all_2)
